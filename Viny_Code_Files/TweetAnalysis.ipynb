{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9869f6a3-52a2-40e5-8e73-0540778362d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import hvplot.pandas\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f64f3a71-0440-4de2-ae7f-2e101c69dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import tweet date csv files as dataframes.\n",
    "dates_df = pd.read_csv(Path(\"duoldates.csv\"),)\n",
    "dates_df2 = pd.read_csv(Path(\"vtexdates.csv\"),)\n",
    "dates_df3 = pd.read_csv(Path(\"skyadates.csv\"),)\n",
    "dates_df4 = pd.read_csv(Path(\"cpngdates.csv\"),)\n",
    "dates_df5 = pd.read_csv(Path(\"vziodates.csv\"),)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33f9c27c-aabf-4729-9dba-0dc78746a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframes with just the date column from the csv read, and run the counter function to get a count of Tweets on each date.\n",
    "#Create a dictionary from the counter object, and create a dataframe for each ticker.\n",
    "date_count = dates_df[\"date\"]\n",
    "date_count = Counter(date_count)\n",
    "date_dict = dict(date_count)\n",
    "date_dict = pd.DataFrame(date_dict.items(), columns = ['Date', 'TweetCount'])\n",
    "\n",
    "date_count2 = dates_df2[\"date\"]\n",
    "date_count2 = Counter(date_count2)\n",
    "date_dict2 = dict(date_count2)\n",
    "date_dict2 = pd.DataFrame(date_dict2.items(), columns = ['Date', 'TweetCount'])\n",
    "\n",
    "date_count3 = dates_df3[\"date\"]\n",
    "date_count3 = Counter(date_count3)\n",
    "date_dict3 = dict(date_count3)\n",
    "date_dict3 = pd.DataFrame(date_dict3.items(), columns = ['Date', 'TweetCount'])\n",
    "\n",
    "date_count4 = dates_df4[\"date\"]\n",
    "date_count4 = Counter(date_count4)\n",
    "date_dict4 = dict(date_count4)\n",
    "date_dict4 = pd.DataFrame(date_dict4.items(), columns = ['Date', 'TweetCount'])\n",
    "\n",
    "date_count5 = dates_df5[\"date\"]\n",
    "date_count5 = Counter(date_count5)\n",
    "date_dict5 = dict(date_count5)\n",
    "date_dict5 = pd.DataFrame(date_dict5.items(), columns = ['Date', 'TweetCount'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b1304dd-70a0-4883-833f-8df957ce8b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load Alpaca and env file information.\n",
    "load_dotenv()\n",
    "alpaca_api_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "# Check the values were imported correctly by evaluating the type of each\n",
    "display(type(alpaca_api_key))\n",
    "display(type(alpaca_secret_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "575d80cd-4859-4405-bcbe-064d19ac5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your Alpaca API REST object by calling Alpaca's tradeapi.REST function\n",
    "# Set the parameters to your alpaca_api_key, alpaca_secret_key and api_version=\"v2\" \n",
    "alpaca = tradeapi.REST(\n",
    "    alpaca_api_key,\n",
    "    alpaca_secret_key,\n",
    "    api_version=\"v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6bda8af3-447a-4847-a93b-1b88a5a39613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set 1 Day increments and limit return to 1000 rows.\n",
    "timeframe = \"1D\"\n",
    "limit_rows = 1000\n",
    "#Set start and end dates to match tweet information\n",
    "start_date = pd.Timestamp(\"2021-07-27\", tz=\"America/New_York\").isoformat()\n",
    "end_date = pd.Timestamp(\"2021-10-27\", tz=\"America/New_York\").isoformat()\n",
    "start_date2 = pd.Timestamp(\"2021-07-20\", tz=\"America/New_York\").isoformat()\n",
    "end_date2 = pd.Timestamp(\"2021-10-20\", tz=\"America/New_York\").isoformat()\n",
    "start_date3 = pd.Timestamp(\"2021-05-18\", tz=\"America/New_York\").isoformat()\n",
    "end_date3 = pd.Timestamp(\"2021-08-18\", tz=\"America/New_York\").isoformat()\n",
    "start_date4 = pd.Timestamp(\"2021-03-10\", tz=\"America/New_York\").isoformat()\n",
    "end_date4 = pd.Timestamp(\"2021-06-10\", tz=\"America/New_York\").isoformat()\n",
    "start_date5 = pd.Timestamp(\"2021-03-24\", tz=\"America/New_York\").isoformat()\n",
    "end_date5 = pd.Timestamp(\"2021-06-24\", tz=\"America/New_York\").isoformat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e9ae00d-beb1-4c06-b795-ea237d787bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull Alpaca Data for each ticker and timeset.\n",
    "prices_df = alpaca.get_barset(\n",
    "    \"DUOL\",\n",
    "    timeframe,\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    limit=limit_rows\n",
    ").df\n",
    "\n",
    "prices_df2 = alpaca.get_barset(\n",
    "    \"VTEX\",\n",
    "    timeframe,\n",
    "    start=start_date2,\n",
    "    end=end_date2,\n",
    "    limit=limit_rows\n",
    ").df\n",
    "\n",
    "prices_df3 = alpaca.get_barset(\n",
    "    \"SKYA\",\n",
    "    timeframe,\n",
    "    start=start_date3,\n",
    "    end=end_date3,\n",
    "    limit=limit_rows\n",
    ").df\n",
    "\n",
    "prices_df4 = alpaca.get_barset(\n",
    "    \"CPNG\",\n",
    "    timeframe,\n",
    "    start=start_date4,\n",
    "    end=end_date4,\n",
    "    limit=limit_rows\n",
    ").df\n",
    "\n",
    "prices_df5 = alpaca.get_barset(\n",
    "    \"VZIO\",\n",
    "    timeframe,\n",
    "    start=start_date5,\n",
    "    end=end_date5,\n",
    "    limit=limit_rows\n",
    ").df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e71f9bc-193f-4e31-b127-2b60cdd70517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove timestamp from alapaca dataframe time column. Create new dataframe with time, close, and volume.\n",
    "prices_df.reset_index(level=0, inplace=True)\n",
    "prices_df[\"time\"] = pd.to_datetime(prices_df[\"time\"]).dt.date\n",
    "prices_df = [prices_df[\"time\"], prices_df[\"DUOL\", \"close\"], prices_df[\"DUOL\", \"volume\"]]\n",
    "prices_df = pd.DataFrame(prices_df)\n",
    "prices_df = prices_df.T\n",
    "prices_df.columns = [\"Time\", \"Close\", \"Volume\"]\n",
    "\n",
    "prices_df2.reset_index(level=0, inplace=True)\n",
    "prices_df2[\"time\"] = pd.to_datetime(prices_df2[\"time\"]).dt.date\n",
    "prices_df2 = [prices_df2[\"time\"], prices_df2[\"VTEX\", \"close\"], prices_df2[\"VTEX\", \"volume\"]]\n",
    "prices_df2 = pd.DataFrame(prices_df2)\n",
    "prices_df2 = prices_df2.T\n",
    "prices_df2.columns = [\"Time\", \"Close\", \"Volume\"]\n",
    "\n",
    "\n",
    "prices_df3.reset_index(level=0, inplace=True)\n",
    "prices_df3[\"time\"] = pd.to_datetime(prices_df3[\"time\"]).dt.date\n",
    "prices_df3 = [prices_df3[\"time\"], prices_df3[\"SKYA\", \"close\"], prices_df3[\"SKYA\", \"volume\"]]\n",
    "prices_df3 = pd.DataFrame(prices_df3)\n",
    "prices_df3 = prices_df3.T\n",
    "prices_df3.columns = [\"Time\", \"Close\", \"Volume\"]\n",
    "\n",
    "\n",
    "prices_df4.reset_index(level=0, inplace=True)\n",
    "prices_df4[\"time\"] = pd.to_datetime(prices_df4[\"time\"]).dt.date\n",
    "prices_df4 = [prices_df4[\"time\"], prices_df4[\"CPNG\", \"close\"], prices_df4[\"CPNG\", \"volume\"]]\n",
    "prices_df4 = pd.DataFrame(prices_df4)\n",
    "prices_df4 = prices_df4.T\n",
    "prices_df4.columns = [\"Time\", \"Close\", \"Volume\"]\n",
    "\n",
    "\n",
    "prices_df5.reset_index(level=0, inplace=True)\n",
    "prices_df5[\"time\"] = pd.to_datetime(prices_df5[\"time\"]).dt.date\n",
    "prices_df5 = [prices_df5[\"time\"], prices_df5[\"VZIO\", \"close\"], prices_df5[\"VZIO\", \"volume\"]]\n",
    "prices_df5 = pd.DataFrame(prices_df5)\n",
    "prices_df5 = prices_df5.T\n",
    "prices_df5.columns = [\"Time\", \"Close\", \"Volume\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "14a76a8c-38d2-4b89-a342-03c87621d104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(sqlite:///)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create SQL database to join price and tweet dataframes for each ticker.\n",
    "# Create the connection string for your SQLite database\n",
    "database_connection_string = 'sqlite:///'\n",
    "\n",
    "# Pass the connection string to the SQLAlchemy create_engine function\n",
    "engine = sqlalchemy.create_engine(database_connection_string)\n",
    "\n",
    "# Confirm that the database engine was created.\n",
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4eaaea8e-e6b1-4f47-881e-2cbf2c26296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import each price and tweet count table into the database.\n",
    "date_dict.to_sql(\n",
    "    'date', \n",
    "    engine, \n",
    "    index=False, \n",
    "    if_exists='replace'\n",
    ")\n",
    "date_dict2.to_sql(\n",
    "    'date2', \n",
    "    engine, \n",
    "    index=False, \n",
    "    if_exists='replace'\n",
    ")\n",
    "date_dict3.to_sql(\n",
    "    'date3', \n",
    "    engine, \n",
    "    index=False, \n",
    "    if_exists='replace'\n",
    ")\n",
    "date_dict4.to_sql(\n",
    "    'date4', \n",
    "    engine, \n",
    "    index=False, \n",
    "    if_exists='replace'\n",
    ")\n",
    "date_dict5.to_sql(\n",
    "    'date5', \n",
    "    engine, \n",
    "    index=False, \n",
    "    if_exists='replace'\n",
    ")\n",
    "prices_df.to_sql(\n",
    "    'prices', \n",
    "    engine, \n",
    "    index=False, \n",
    "    if_exists='replace'\n",
    ")\n",
    "prices_df2.to_sql(\n",
    "    'prices2', \n",
    "    engine, \n",
    "    index=False, \n",
    "    if_exists='replace'\n",
    ")\n",
    "prices_df3.to_sql(\n",
    "    'prices3', \n",
    "    engine, \n",
    "    index=False, \n",
    "    if_exists='replace'\n",
    ")\n",
    "prices_df4.to_sql(\n",
    "    'prices4', \n",
    "    engine, \n",
    "    index=False, \n",
    "    if_exists='replace'\n",
    ")\n",
    "prices_df5.to_sql(\n",
    "    'prices5', \n",
    "    engine, \n",
    "    index=False, \n",
    "    if_exists='replace'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "663d8177-fd28-4914-981f-d1a987b4dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create queries to join price and tweet count tables for each ticker by date.\n",
    "query = \"\"\"\n",
    "SELECT date.Date, date.TweetCount, prices.Close, prices.Volume\n",
    "FROM prices\n",
    "JOIN date ON date.Date = prices.Time\n",
    "\"\"\"\n",
    "\n",
    "query2 = \"\"\"\n",
    "SELECT date2.Date, date2.TweetCount, prices2.Close, prices2.Volume\n",
    "FROM prices2\n",
    "JOIN date2 ON date2.Date = prices2.Time\n",
    "\"\"\"\n",
    "\n",
    "query3 = \"\"\"\n",
    "SELECT date3.Date, date3.TweetCount, prices3.Close, prices3.Volume\n",
    "FROM prices3\n",
    "JOIN date3 ON date3.Date = prices3.Time\n",
    "\"\"\"\n",
    "\n",
    "query4 = \"\"\"\n",
    "SELECT date4.Date, date4.TweetCount, prices4.Close, prices4.Volume\n",
    "FROM prices4\n",
    "JOIN date4 ON date4.Date = prices4.Time\n",
    "\"\"\"\n",
    "\n",
    "query5 = \"\"\"\n",
    "SELECT date5.Date, date5.TweetCount, prices5.Close, prices5.Volume\n",
    "FROM prices5\n",
    "JOIN date5 ON date5.Date = prices5.Time\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17cb4c2a-9a7e-415d-87b8-a7c776426426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run SQL queries and create dataframe for each ticker.\n",
    "DUOL_df = pd.read_sql_query(query, con=engine)\n",
    "VTEX_df = pd.read_sql_query(query2, con=engine)\n",
    "SKYA_df = pd.read_sql_query(query3, con=engine)\n",
    "CPNG_df = pd.read_sql_query(query4, con=engine)\n",
    "VZIO_df = pd.read_sql_query(query5, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e622218-0c25-4665-b89a-814575d259b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort by date, create perent change columes, and set the index as the Date for each of the ticker dataframes\n",
    "DUOL_df = DUOL_df.sort_values('Date')\n",
    "DUOL_df[\"count_pct_chg\"] = DUOL_df[\"TweetCount\"].pct_change()\n",
    "DUOL_df[\"close_pct_chg\"] = DUOL_df[\"Close\"].pct_change()\n",
    "DUOL_df[\"vol_pct_chg\"] = DUOL_df[\"Volume\"].pct_change()\n",
    "DUOL_df = DUOL_df.set_index(\"Date\")\n",
    "DUOL_df = DUOL_df.dropna()\n",
    "DUOL_df\n",
    "\n",
    "VTEX_df = VTEX_df.sort_values('Date')\n",
    "VTEX_df[\"count_pct_chg\"] = VTEX_df[\"TweetCount\"].pct_change()\n",
    "VTEX_df[\"close_pct_chg\"] = VTEX_df[\"Close\"].pct_change()\n",
    "VTEX_df[\"vol_pct_chg\"] = VTEX_df[\"Volume\"].pct_change()\n",
    "VTEX_df = VTEX_df.set_index(\"Date\")\n",
    "VTEX_df = VTEX_df.dropna()\n",
    "\n",
    "\n",
    "SKYA_df = SKYA_df.sort_values('Date')\n",
    "SKYA_df[\"count_pct_chg\"] = SKYA_df[\"TweetCount\"].pct_change()\n",
    "SKYA_df[\"close_pct_chg\"] = SKYA_df[\"Close\"].pct_change()\n",
    "SKYA_df[\"vol_pct_chg\"] = SKYA_df[\"Volume\"].pct_change()\n",
    "SKYA_df = SKYA_df.set_index(\"Date\")\n",
    "SKYA_df = SKYA_df.dropna()\n",
    "SKYA_df\n",
    "\n",
    "CPNG_df = CPNG_df.sort_values('Date')\n",
    "CPNG_df[\"count_pct_chg\"] = CPNG_df[\"TweetCount\"].pct_change()\n",
    "CPNG_df[\"close_pct_chg\"] = CPNG_df[\"Close\"].pct_change()\n",
    "CPNG_df[\"vol_pct_chg\"] = CPNG_df[\"Volume\"].pct_change()\n",
    "CPNG_df = CPNG_df.set_index(\"Date\")\n",
    "CPNG_df = CPNG_df.dropna()\n",
    "CPNG_df\n",
    "\n",
    "VZIO_df = VZIO_df.sort_values('Date')\n",
    "VZIO_df[\"count_pct_chg\"] = VZIO_df[\"TweetCount\"].pct_change()\n",
    "VZIO_df[\"close_pct_chg\"] = VZIO_df[\"Close\"].pct_change()\n",
    "VZIO_df[\"vol_pct_chg\"] = VZIO_df[\"Volume\"].pct_change()\n",
    "VZIO_df = VZIO_df.set_index(\"Date\")\n",
    "VZIO_df = VZIO_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1c435e0-aa50-41db-bfef-7601293eed75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.317021343622952, 0.7985343769277501]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get Tweet Count correlation to close price and volume for 1 ticker.\n",
    "VZIO_corr = VZIO_df.corr()\n",
    "VZIO = [VZIO_corr.iloc[1,0], VZIO_corr.iloc[2,0]]\n",
    "VZIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9eec3d89-a66b-45b7-a1d7-d723a7955a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_Corr</th>\n",
       "      <th>Vol_Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VZIO</th>\n",
       "      <td>0.317021</td>\n",
       "      <td>0.798534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Close_Corr  Vol_Corr\n",
       "VZIO    0.317021  0.798534"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert resulting data into dataframe, transpose, and rename colums\n",
    "correlations = pd.DataFrame(VZIO)\n",
    "correlations = correlations.T\n",
    "correlations\n",
    "correlations.rename(columns = {0 : \"Close_Corr\", 1 : \"Vol_Corr\"}, index = {0 : \"VZIO\"}, inplace = True)\n",
    "correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf5be79d-b92c-49b2-b2ef-7549578035e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_Corr</th>\n",
       "      <th>Vol_Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VZIO</th>\n",
       "      <td>0.317021</td>\n",
       "      <td>0.798534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CPNG</th>\n",
       "      <td>0.155385</td>\n",
       "      <td>0.901528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKYA</th>\n",
       "      <td>0.565607</td>\n",
       "      <td>0.223653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VTEX</th>\n",
       "      <td>-0.083310</td>\n",
       "      <td>0.580507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DUOL</th>\n",
       "      <td>0.154836</td>\n",
       "      <td>0.390002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Close_Corr  Vol_Corr\n",
       "VZIO    0.317021  0.798534\n",
       "CPNG    0.155385  0.901528\n",
       "SKYA    0.565607  0.223653\n",
       "VTEX   -0.083310  0.580507\n",
       "DUOL    0.154836  0.390002"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CPNG_corr = CPNG_df.corr()\n",
    "CPNG = [CPNG_corr.iloc[1,0], CPNG_corr.iloc[2,0]]\n",
    "CPNG = pd.DataFrame(CPNG)\n",
    "CPNG = CPNG.T\n",
    "CPNG.rename(columns = {0 : \"Close_Corr\", 1 : \"Vol_Corr\"}, index = {0 : \"CPNG\"}, inplace = True)\n",
    "correlations = correlations.append(CPNG)\n",
    "\n",
    "SKYA_corr = SKYA_df.corr()\n",
    "SKYA = [SKYA_corr.iloc[1,0], SKYA_corr.iloc[2,0]]\n",
    "SKYA = pd.DataFrame(SKYA)\n",
    "SKYA = SKYA.T\n",
    "SKYA.rename(columns = {0 : \"Close_Corr\", 1 : \"Vol_Corr\"}, index = {0 : \"SKYA\"}, inplace = True)\n",
    "correlations = correlations.append(SKYA)\n",
    "\n",
    "VTEX_corr = VTEX_df.corr()\n",
    "VTEX = [VTEX_corr.iloc[1,0], VTEX_corr.iloc[2,0]]\n",
    "VTEX = pd.DataFrame(VTEX)\n",
    "VTEX = VTEX.T\n",
    "VTEX.rename(columns = {0 : \"Close_Corr\", 1 : \"Vol_Corr\"}, index = {0 : \"VTEX\"}, inplace = True)\n",
    "correlations = correlations.append(VTEX)\n",
    "\n",
    "DUOL_corr = DUOL_df.corr()\n",
    "DUOL_corr\n",
    "DUOL = [DUOL_corr.iloc[1,0], DUOL_corr.iloc[2,0]]\n",
    "DUOL = pd.DataFrame(DUOL)\n",
    "DUOL = DUOL.T\n",
    "DUOL.rename(columns = {0 : \"Close_Corr\", 1 : \"Vol_Corr\"}, index = {0 : \"DUOL\"}, inplace = True)\n",
    "correlations = correlations.append(DUOL)\n",
    "correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f74f4f81-71a8-40f7-be2c-6bb785e07f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations.to_csv('vncorrelations.csv')\n",
    "CPNG_df.to_csv('CPNGStockData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d1d19d-2548-4fca-a9ed-f1f9bf08ad43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
